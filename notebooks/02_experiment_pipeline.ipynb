{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6d0285",
   "metadata": {},
   "source": [
    "# Part 2: Stratified Sampling & Classic ML Baseline\n",
    "\n",
    "Uses `data/asrs_multilabel.csv` (172K rows) from notebook 01.\n",
    "1. Stratified 40K sample -> 32K train / 8K test\n",
    "2. TF-IDF + XGBoost multi-label baseline\n",
    "3. Structured feature extraction\n",
    "4. Modal LLM script scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e88c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:47.211897Z",
     "iopub.status.busy": "2026-02-12T19:08:47.211664Z",
     "iopub.status.idle": "2026-02-12T19:08:52.373541Z",
     "shell.execute_reply": "2026-02-12T19:08:52.371507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "for pkg in [\"iterative-stratification\", \"tqdm\"]:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time, glob, warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RAW_DIR = \"../raw data\"\n",
    "DATA_DIR = \"../data\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "SCRIPTS_DIR = \"../scripts\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(SCRIPTS_DIR, exist_ok=True)\n",
    "\n",
    "@contextmanager\n",
    "def timer(label):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f\"  [{label}] {time.time() - t0:.1f}s\")\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2468038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:52.377915Z",
     "iopub.status.busy": "2026-02-12T19:08:52.377227Z",
     "iopub.status.idle": "2026-02-12T19:08:55.885135Z",
     "shell.execute_reply": "2026-02-12T19:08:55.883547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: train_set.csv and test_set.csv already exist, loading...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full: 172,183  Train: 31,850  Test: 8,044\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Data & Create 40K Stratified Sample\n",
    "\n",
    "train_path = os.path.join(DATA_DIR, \"train_set.csv\")\n",
    "test_path = os.path.join(DATA_DIR, \"test_set.csv\")\n",
    "\n",
    "if os.path.exists(train_path) and os.path.exists(test_path):\n",
    "    print(\"Checkpoint: train_set.csv and test_set.csv already exist, loading...\")\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    full_df = pd.read_csv(os.path.join(DATA_DIR, \"asrs_multilabel.csv\"))\n",
    "    LABEL_COLS = [c for c in full_df.columns if c not in (\"ACN\", \"Narrative\")]\n",
    "    print(f\"Full: {len(full_df):,}  Train: {len(train_df):,}  Test: {len(test_df):,}\")\n",
    "else:\n",
    "    with timer(\"Load full dataset\"):\n",
    "        full_df = pd.read_csv(os.path.join(DATA_DIR, \"asrs_multilabel.csv\"))\n",
    "        print(f\"Loaded {len(full_df):,} rows\")\n",
    "\n",
    "    LABEL_COLS = [c for c in full_df.columns if c not in (\"ACN\", \"Narrative\")]\n",
    "    print(f\"Label columns ({len(LABEL_COLS)}): {LABEL_COLS}\")\n",
    "\n",
    "    y_full = full_df[LABEL_COLS].values\n",
    "    X_idx = np.arange(len(full_df))\n",
    "\n",
    "    # Step 1: draw 40K stratified sample from 172K\n",
    "    with timer(\"40K stratified sample\"):\n",
    "        splitter_40k = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=40_000, random_state=42)\n",
    "        _, sample_idx = next(splitter_40k.split(X_idx, y_full))\n",
    "        sample_df = full_df.iloc[sample_idx].reset_index(drop=True)\n",
    "        print(f\"Sample size: {len(sample_df):,}\")\n",
    "\n",
    "    # Step 2: split 40K -> 32K train / 8K test\n",
    "    with timer(\"32K/8K split\"):\n",
    "        y_sample = sample_df[LABEL_COLS].values\n",
    "        X_sample_idx = np.arange(len(sample_df))\n",
    "        splitter_split = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=8_000, random_state=42)\n",
    "        train_idx, test_idx = next(splitter_split.split(X_sample_idx, y_sample))\n",
    "        train_df = sample_df.iloc[train_idx].reset_index(drop=True)\n",
    "        test_df = sample_df.iloc[test_idx].reset_index(drop=True)\n",
    "        print(f\"Train: {len(train_df):,}  Test: {len(test_df):,}\")\n",
    "\n",
    "    train_df.to_csv(train_path, index=False)\n",
    "    test_df.to_csv(test_path, index=False)\n",
    "    print(f\"Saved {train_path} and {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7012b99f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:55.889390Z",
     "iopub.status.busy": "2026-02-12T19:08:55.889010Z",
     "iopub.status.idle": "2026-02-12T19:08:55.922927Z",
     "shell.execute_reply": "2026-02-12T19:08:55.921173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                         Full %  Train %   Test %\n",
      "--------------------------------------------------------\n",
      "Aircraft Equipment Problem       28.64%   28.75%   28.56%\n",
      "Airspace Violation                3.97%    3.99%    3.95%\n",
      "ATC Issue                        17.09%   17.16%   17.04%\n",
      "Conflict                         26.88%   26.99%   26.80%\n",
      "Deviation - Altitude             16.48%   16.54%   16.43%\n",
      "Deviation - Procedural           65.40%   65.66%   65.22%\n",
      "Deviation - Speed                 2.90%    2.92%    2.90%\n",
      "Deviation - Track/Heading        11.77%   11.82%   11.74%\n",
      "Flight Deck/Cabin Event           7.14%    7.16%    7.12%\n",
      "Ground Event/Encounter            8.27%    8.30%    8.24%\n",
      "Ground Excursion                  2.16%    2.17%    2.15%\n",
      "Ground Incursion                  7.32%    7.35%    7.30%\n",
      "Inflight Event/Encounter         22.45%   22.54%   22.39%\n",
      "\n",
      "Label Count Distribution\n",
      "# Labels      Train     Test\n",
      "----------------------------\n",
      "1             6,936    1,770\n",
      "2            14,440    3,680\n",
      "3             7,723    1,951\n",
      "4             2,297      529\n",
      "5+              454      114\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Stratification Quality Check\n",
    "\n",
    "print(f\"{'Category':<30} {'Full %':>8} {'Train %':>8} {'Test %':>8}\")\n",
    "print(\"-\" * 56)\n",
    "for col in LABEL_COLS:\n",
    "    pf = full_df[col].mean() * 100\n",
    "    pt = train_df[col].mean() * 100\n",
    "    pe = test_df[col].mean() * 100\n",
    "    print(f\"{col:<30} {pf:>7.2f}% {pt:>7.2f}% {pe:>7.2f}%\")\n",
    "\n",
    "print(f\"\\nLabel Count Distribution\")\n",
    "print(f\"{'# Labels':<10} {'Train':>8} {'Test':>8}\")\n",
    "print(\"-\" * 28)\n",
    "train_lc = train_df[LABEL_COLS].sum(axis=1)\n",
    "test_lc = test_df[LABEL_COLS].sum(axis=1)\n",
    "for n in sorted(set(train_lc.unique()) | set(test_lc.unique())):\n",
    "    label = f\"{int(n)}\" if n < 5 else \"5+\"\n",
    "    if n >= 5 and n > min(x for x in (set(train_lc.unique()) | set(test_lc.unique())) if x >= 5):\n",
    "        continue\n",
    "    if n < 5:\n",
    "        tr_cnt = (train_lc == n).sum()\n",
    "        te_cnt = (test_lc == n).sum()\n",
    "    else:\n",
    "        tr_cnt = (train_lc >= 5).sum()\n",
    "        te_cnt = (test_lc >= 5).sum()\n",
    "    print(f\"{label:<10} {tr_cnt:>8,} {te_cnt:>8,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394bbce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:55.927648Z",
     "iopub.status.busy": "2026-02-12T19:08:55.927295Z",
     "iopub.status.idle": "2026-02-12T19:08:55.980622Z",
     "shell.execute_reply": "2026-02-12T19:08:55.979321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: predictions and metrics exist, loading...\n",
      "                  Category  Precision   Recall       F1  ROC-AUC\n",
      "Aircraft Equipment Problem   0.813420 0.818024 0.815715 0.943793\n",
      "        Airspace Violation   0.480435 0.694969 0.568123 0.937690\n",
      "                 ATC Issue   0.605263 0.754923 0.671860 0.915598\n",
      "                  Conflict   0.769099 0.835807 0.801067 0.943318\n",
      "      Deviation - Altitude   0.663563 0.808623 0.728946 0.949377\n",
      "    Deviation - Procedural   0.811718 0.779070 0.795059 0.794006\n",
      "         Deviation - Speed   0.550781 0.605150 0.576687 0.948998\n",
      " Deviation - Track/Heading   0.591959 0.733051 0.654993 0.927470\n",
      "   Flight Deck/Cabin Event   0.701258 0.778360 0.737800 0.963287\n",
      "    Ground Event/Encounter   0.503165 0.719457 0.592179 0.923195\n",
      "          Ground Excursion   0.572254 0.572254 0.572254 0.973433\n",
      "          Ground Incursion   0.645669 0.838160 0.729429 0.975834\n",
      "  Inflight Event/Encounter   0.704499 0.765130 0.733564 0.920235\n",
      "                     MACRO   0.647160 0.746383 0.690591 0.932018\n",
      "                     MICRO   0.713408 0.781384 0.745851 0.949953\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: TF-IDF + XGBoost (13 binary classifiers)\n",
    "\n",
    "pred_path = os.path.join(RESULTS_DIR, \"classic_ml_text_predictions.csv\")\n",
    "metrics_path = os.path.join(RESULTS_DIR, \"classic_ml_text_metrics.csv\")\n",
    "\n",
    "if os.path.exists(pred_path) and os.path.exists(metrics_path):\n",
    "    print(\"Checkpoint: predictions and metrics exist, loading...\")\n",
    "    predictions_df = pd.read_csv(pred_path)\n",
    "    metrics_df = pd.read_csv(metrics_path)\n",
    "    print(metrics_df.to_string(index=False))\n",
    "else:\n",
    "    # Fit TF-IDF\n",
    "    with timer(\"TF-IDF vectorization\"):\n",
    "        tfidf = TfidfVectorizer(\n",
    "            max_features=50_000,\n",
    "            ngram_range=(1, 2),\n",
    "            sublinear_tf=True,\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        X_train = tfidf.fit_transform(train_df[\"Narrative\"])\n",
    "        X_test = tfidf.transform(test_df[\"Narrative\"])\n",
    "        print(f\"TF-IDF shape: train {X_train.shape}, test {X_test.shape}\")\n",
    "\n",
    "    # Train one classifier per category\n",
    "    results = []\n",
    "    all_preds = {\"ACN\": test_df[\"ACN\"].values}\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    for i, col in enumerate(LABEL_COLS):\n",
    "        t0 = time.time()\n",
    "        y_tr = train_df[col].values\n",
    "        y_te = test_df[col].values\n",
    "\n",
    "        n_pos = y_tr.sum()\n",
    "        n_neg = len(y_tr) - n_pos\n",
    "        spw = n_neg / n_pos if n_pos > 0 else 1.0\n",
    "\n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            scale_pos_weight=spw,\n",
    "            n_jobs=-1,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "            verbosity=0,\n",
    "            tree_method=\"hist\",\n",
    "        )\n",
    "        clf.fit(X_train, y_tr)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        p = precision_score(y_te, y_pred, zero_division=0)\n",
    "        r = recall_score(y_te, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_te, y_pred, zero_division=0)\n",
    "        auc = roc_auc_score(y_te, y_proba)\n",
    "        elapsed = time.time() - t0\n",
    "\n",
    "        results.append({\"Category\": col, \"Precision\": p, \"Recall\": r, \"F1\": f1, \"ROC-AUC\": auc})\n",
    "        all_preds[f\"{col}_true\"] = y_te\n",
    "        all_preds[f\"{col}_pred\"] = y_pred\n",
    "        all_preds[f\"{col}_proba\"] = y_proba\n",
    "        print(f\"  [{i+1}/{len(LABEL_COLS)}] {col:<30} P={p:.3f} R={r:.3f} F1={f1:.3f} AUC={auc:.3f}  ({elapsed:.1f}s)\")\n",
    "\n",
    "    total_elapsed = time.time() - total_t0\n",
    "    print(f\"\\nTotal training time: {total_elapsed:.1f}s\")\n",
    "\n",
    "    # Compute macro and micro aggregates\n",
    "    y_true_all = test_df[LABEL_COLS].values\n",
    "    y_pred_all = np.column_stack([all_preds[f\"{c}_pred\"] for c in LABEL_COLS])\n",
    "    y_proba_all = np.column_stack([all_preds[f\"{c}_proba\"] for c in LABEL_COLS])\n",
    "\n",
    "    macro_p = precision_score(y_true_all, y_pred_all, average=\"macro\", zero_division=0)\n",
    "    macro_r = recall_score(y_true_all, y_pred_all, average=\"macro\", zero_division=0)\n",
    "    macro_f1 = f1_score(y_true_all, y_pred_all, average=\"macro\", zero_division=0)\n",
    "    macro_auc = roc_auc_score(y_true_all, y_proba_all, average=\"macro\")\n",
    "\n",
    "    micro_p = precision_score(y_true_all, y_pred_all, average=\"micro\", zero_division=0)\n",
    "    micro_r = recall_score(y_true_all, y_pred_all, average=\"micro\", zero_division=0)\n",
    "    micro_f1 = f1_score(y_true_all, y_pred_all, average=\"micro\", zero_division=0)\n",
    "    micro_auc = roc_auc_score(y_true_all, y_proba_all, average=\"micro\")\n",
    "\n",
    "    results.append({\"Category\": \"MACRO\", \"Precision\": macro_p, \"Recall\": macro_r, \"F1\": macro_f1, \"ROC-AUC\": macro_auc})\n",
    "    results.append({\"Category\": \"MICRO\", \"Precision\": micro_p, \"Recall\": micro_r, \"F1\": micro_f1, \"ROC-AUC\": micro_auc})\n",
    "\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "    predictions_df = pd.DataFrame(all_preds)\n",
    "    predictions_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    print(f\"\\nSaved {metrics_path} and {pred_path}\")\n",
    "    print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118220c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:55.983756Z",
     "iopub.status.busy": "2026-02-12T19:08:55.983537Z",
     "iopub.status.idle": "2026-02-12T19:08:56.060723Z",
     "shell.execute_reply": "2026-02-12T19:08:56.059645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: structured_features.csv exists, loading...\n",
      "Shape: (39894, 7)\n",
      "\n",
      "============================================================\n",
      "\n",
      "Local Time Of Day (5 unique, 2380 missing):\n",
      "Local Time Of Day\n",
      "1201-1800    14980\n",
      "0601-1200    11655\n",
      "1801-2400     8281\n",
      "0001-0600     2591\n",
      "ZZZ              7\n",
      "\n",
      "Light (4 unique, 8612 missing):\n",
      "Light\n",
      "Daylight    23139\n",
      "Night        6010\n",
      "Dusk         1524\n",
      "Dawn          609\n",
      "\n",
      "Flight Phase (971 unique, 1032 missing):\n",
      "Flight Phase\n",
      "Cruise              4851\n",
      "Initial Approach    4037\n",
      "Climb               3751\n",
      "Taxi                3219\n",
      "Parked              2586\n",
      "Descent             2257\n",
      "Landing             1989\n",
      "Cruise; Cruise      1947\n",
      "Takeoff / Launch    1822\n",
      "Initial Climb       1464\n",
      "\n",
      "Make Model Name (655 unique, 250 missing):\n",
      "Make Model Name\n",
      "Commercial Fixed Wing                                     3062\n",
      "Medium Large Transport; Low Wing; 2 Turbojet Eng          1860\n",
      "Any Unknown or Unlisted Aircraft Manufacturer             1223\n",
      "Skyhawk 172/Cutlass 172                                   1186\n",
      "B737 Undifferentiated or Other Model                      1031\n",
      "MD-80 Series (DC-9-80) Undifferentiated or Other Model    1027\n",
      "A320                                                       999\n",
      "Small Aircraft; High Wing; 1 Eng; Fixed Gear               899\n",
      "B737-300                                                   732\n",
      "Large Transport; Low Wing; 3 Turbojet Eng                  711\n",
      "\n",
      "Weather Elements / Visibility (1041 unique, 25294 missing):\n",
      "Weather Elements / Visibility\n",
      "10            4041\n",
      "10.0           551\n",
      "20             528\n",
      "5              482\n",
      "Turbulence     416\n",
      "6              351\n",
      "15             308\n",
      "20.0           297\n",
      "5.0            288\n",
      "15.0           284\n",
      "\n",
      "Locale Reference (5595 unique, 1344 missing):\n",
      "Locale Reference\n",
      "ZZZ.Airport     7535\n",
      "ZZZ.ARTCC       1113\n",
      "ZZZ.TRACON       631\n",
      "ZZZZ.Airport     381\n",
      "ORD.Airport      378\n",
      "LAX.Airport      297\n",
      "LAX              283\n",
      "ZZZ.Tower        280\n",
      "DFW.Airport      278\n",
      "TEB.Airport      270\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Structured Features Extraction from Raw CSVs\n",
    "\n",
    "struct_path = os.path.join(DATA_DIR, \"structured_features.csv\")\n",
    "\n",
    "if os.path.exists(struct_path):\n",
    "    print(\"Checkpoint: structured_features.csv exists, loading...\")\n",
    "    struct_df = pd.read_csv(struct_path)\n",
    "    print(f\"Shape: {struct_df.shape}\")\n",
    "else:\n",
    "    target_cols = [\"ACN\", \"Local Time Of Day\", \"Light\", \"Flight Phase\",\n",
    "                   \"Make Model Name\", \"Weather Elements / Visibility\", \"Locale Reference\"]\n",
    "\n",
    "    sample_acns = set(train_df[\"ACN\"].tolist() + test_df[\"ACN\"].tolist())\n",
    "    print(f\"Looking for {len(sample_acns):,} ACNs in raw CSVs\")\n",
    "\n",
    "    raw_files = sorted(glob.glob(os.path.join(RAW_DIR, \"*.csv\")))\n",
    "    chunks = []\n",
    "\n",
    "    with timer(\"Read raw CSVs\"):\n",
    "        for i, f in enumerate(raw_files):\n",
    "            df_raw = pd.read_csv(\n",
    "                f, header=1, low_memory=False,\n",
    "                usecols=lambda c: c.strip() in target_cols,\n",
    "            )\n",
    "            df_raw.columns = df_raw.columns.str.strip()\n",
    "            df_raw = df_raw[df_raw[\"ACN\"].isin(sample_acns)]\n",
    "            if len(df_raw) > 0:\n",
    "                chunks.append(df_raw)\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Read {i+1}/{len(raw_files)} files...\")\n",
    "\n",
    "    struct_all = pd.concat(chunks, ignore_index=True)\n",
    "    print(f\"Total rows before dedup: {len(struct_all):,}\")\n",
    "\n",
    "    def first_non_null(s):\n",
    "        vals = s.dropna()\n",
    "        return vals.iloc[0] if len(vals) > 0 else np.nan\n",
    "\n",
    "    struct_df = struct_all.groupby(\"ACN\", sort=False).agg(\n",
    "        {c: first_non_null for c in target_cols if c != \"ACN\"}\n",
    "    ).reset_index()\n",
    "    print(f\"After dedup: {len(struct_df):,} rows\")\n",
    "\n",
    "    struct_df.to_csv(struct_path, index=False)\n",
    "    print(f\"Saved {struct_path}\")\n",
    "\n",
    "# Print value distributions\n",
    "print(f\"\\n{'='*60}\")\n",
    "for col in struct_df.columns:\n",
    "    if col == \"ACN\":\n",
    "        continue\n",
    "    n_unique = struct_df[col].nunique()\n",
    "    n_null = struct_df[col].isna().sum()\n",
    "    print(f\"\\n{col} ({n_unique} unique, {n_null} missing):\")\n",
    "    print(struct_df[col].value_counts().head(10).to_string())\n",
    "\n",
    "# TODO: encoding + structured-only XGBoost model deferred to future cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3286a80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:56.063249Z",
     "iopub.status.busy": "2026-02-12T19:08:56.063054Z",
     "iopub.status.idle": "2026-02-12T19:08:56.069838Z",
     "shell.execute_reply": "2026-02-12T19:08:56.068473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: classic_ml_summary.txt exists.\n",
      "Classic ML Baseline: TF-IDF + XGBoost (Text Only)\n",
      "=======================================================\n",
      "Train set: 31,850 reports | Test set: 8,044 reports\n",
      "TF-IDF: max_features=50000, ngram_range=(1,2), sublinear_tf=True\n",
      "XGBoost: n_estimators=300, max_depth=6, lr=0.1, scale_pos_weight=auto\n",
      "\n",
      "Category                        Precision     Recall         F1    ROC-AUC\n",
      "------------------------------------------------------------------------\n",
      "Aircraft Equipment Problem         0.8134     0.8180     0.8157     0.9438\n",
      "Airspace Violation                 0.4804     0.6950     0.5681     0.9377\n",
      "ATC Issue                          0.6053     0.7549     0.6719     0.9156\n",
      "Conflict                           0.7691     0.8358     0.8011     0.9433\n",
      "Deviation - Altitude               0.6636     0.8086     0.7289     0.9494\n",
      "Deviation - Procedural             0.8117     0.7791     0.7951     0.7940\n",
      "Deviation - Speed                  0.5508     0.6052     0.5767     0.9490\n",
      "Deviation - Track/Heading          0.5920     0.7331     0.6550     0.9275\n",
      "Flight Deck/Cabin Event            0.7013     0.7784     0.7378     0.9633\n",
      "Ground Event/Encounter             0.5032     0.7195     0.5922     0.9232\n",
      "Ground Excursion                   0.5723     0.5723     0.5723     0.9734\n",
      "Ground Incursion                   0.6457     0.8382     0.7294     0.9758\n",
      "Inflight Event/Encounter           0.7045     0.7651     0.7336     0.9202\n",
      "------------------------------------------------------------------------\n",
      "MACRO                              0.6472     0.7464     0.6906     0.9320\n",
      "MICRO                              0.7134     0.7814     0.7459     0.9500\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Results Summary\n",
    "\n",
    "summary_path = os.path.join(RESULTS_DIR, \"classic_ml_summary.txt\")\n",
    "\n",
    "if os.path.exists(summary_path):\n",
    "    print(\"Checkpoint: classic_ml_summary.txt exists.\")\n",
    "    with open(summary_path) as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    if \"metrics_df\" not in dir():\n",
    "        metrics_df = pd.read_csv(os.path.join(RESULTS_DIR, \"classic_ml_text_metrics.csv\"))\n",
    "\n",
    "    lines = [\n",
    "        \"Classic ML Baseline: TF-IDF + XGBoost (Text Only)\",\n",
    "        \"=\" * 55,\n",
    "        f\"Train set: {len(train_df):,} reports | Test set: {len(test_df):,} reports\",\n",
    "        f\"TF-IDF: max_features=50000, ngram_range=(1,2), sublinear_tf=True\",\n",
    "        f\"XGBoost: n_estimators=300, max_depth=6, lr=0.1, scale_pos_weight=auto\",\n",
    "        \"\",\n",
    "        f\"{'Category':<30} {'Precision':>10} {'Recall':>10} {'F1':>10} {'ROC-AUC':>10}\",\n",
    "        \"-\" * 72,\n",
    "    ]\n",
    "    for _, row in metrics_df.iterrows():\n",
    "        cat = row[\"Category\"]\n",
    "        sep = \"-\" * 72 if cat == \"MACRO\" else \"\"\n",
    "        if sep:\n",
    "            lines.append(sep)\n",
    "        lines.append(f\"{cat:<30} {row['Precision']:>10.4f} {row['Recall']:>10.4f} {row['F1']:>10.4f} {row['ROC-AUC']:>10.4f}\")\n",
    "\n",
    "    summary = \"\\n\".join(lines)\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        f.write(summary)\n",
    "    print(summary)\n",
    "    print(f\"\\nSaved {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496481e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:56.073597Z",
     "iopub.status.busy": "2026-02-12T19:08:56.073350Z",
     "iopub.status.idle": "2026-02-12T19:08:56.382842Z",
     "shell.execute_reply": "2026-02-12T19:08:56.381526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved classic_ml_f1_barchart.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: F1 Bar Chart Visualization\n",
    "\n",
    "if \"metrics_df\" not in dir():\n",
    "    metrics_df = pd.read_csv(os.path.join(RESULTS_DIR, \"classic_ml_text_metrics.csv\"))\n",
    "\n",
    "cat_metrics = metrics_df[~metrics_df[\"Category\"].isin([\"MACRO\", \"MICRO\"])].copy()\n",
    "cat_metrics = cat_metrics.sort_values(\"F1\", ascending=True)\n",
    "\n",
    "macro_f1 = metrics_df.loc[metrics_df[\"Category\"] == \"MACRO\", \"F1\"].values[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "bars = ax.barh(cat_metrics[\"Category\"], cat_metrics[\"F1\"], color=\"steelblue\", edgecolor=\"white\")\n",
    "ax.axvline(macro_f1, color=\"red\", linestyle=\"--\", linewidth=1.5, label=f\"Macro-F1 = {macro_f1:.3f}\")\n",
    "\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 0.005, bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{width:.3f}\", va=\"center\", fontsize=9)\n",
    "\n",
    "ax.set_xlabel(\"F1 Score\")\n",
    "ax.set_title(\"TF-IDF + XGBoost: Per-Category F1 Scores\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_xlim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"classic_ml_f1_barchart.png\"), dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved classic_ml_f1_barchart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748615d",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Modal LLM Scripts (Zero-Shot, Few-Shot, Fine-Tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58024fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:56.385688Z",
     "iopub.status.busy": "2026-02-12T19:08:56.385435Z",
     "iopub.status.idle": "2026-02-12T19:08:56.391495Z",
     "shell.execute_reply": "2026-02-12T19:08:56.390626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: ../scripts\\modal_zero_shot.py exists.\n",
      "\"\"\"Zero-shot classification of ASRS reports using Llama 3.1 8B-Instruct on Modal.\"\"\"\n",
      "import modal\n",
      "import json\n",
      "import csv\n",
      "import io\n",
      "\n",
      "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
      "GPU = \"L4\"  # 24GB VRAM, ~6GB for 4-bit 8B model\n",
      "\n",
      "app = modal.App(\"asrs-zero-shot\")\n",
      "\n",
      "vllm_image = (\n",
      "    modal.Image.debian_slim(python_version=\"3.11\")\n",
      "    .pip_install(\"vllm\", \"torch\", \"transformers\", \"huggingface_hub\")\n",
      ")\n",
      "\n",
      "\n",
      "@app.cls(\n",
      "    image=vllm_image,\n",
      "    gpu=GPU,\n",
      "    timeout=3600,\n",
      "    secrets=[modal.Secret.from_name\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Verify scripts/modal_zero_shot.py\n",
    "\n",
    "zero_shot_path = os.path.join(SCRIPTS_DIR, \"modal_zero_shot.py\")\n",
    "\n",
    "if os.path.exists(zero_shot_path):\n",
    "    print(f\"Checkpoint: {zero_shot_path} exists.\")\n",
    "    with open(zero_shot_path) as f:\n",
    "        print(f.read()[:500])\n",
    "else:\n",
    "    print(\"ERROR: modal_zero_shot.py not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ed9cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:08:56.394002Z",
     "iopub.status.busy": "2026-02-12T19:08:56.393575Z",
     "iopub.status.idle": "2026-02-12T19:08:56.399595Z",
     "shell.execute_reply": "2026-02-12T19:08:56.398702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: few-shot and fine-tune scripts exist.\n",
      "\n",
      "--- ../scripts\\modal_few_shot.py ---\n",
      "\"\"\"Few-shot classification of ASRS reports using Llama 3.1 8B-Instruct on Modal.\"\"\"\n",
      "import modal\n",
      "import json\n",
      "\n",
      "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
      "GPU = \"L4\"  # 24GB VRAM\n",
      "\n",
      "app = modal.App(\"asrs-few-shot\")\n",
      "\n",
      "vllm_image = (\n",
      "    modal.Image.debian_slim(python_version=\"3.11\")\n",
      "    .pip_install(\"v\n",
      "\n",
      "--- ../scripts\\modal_finetune.py ---\n",
      "\"\"\"QLoRA fine-tuning of Llama 3.1 8B for ASRS report classification on Modal.\"\"\"\n",
      "import modal\n",
      "import json\n",
      "\n",
      "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
      "GPU = \"L4\"  # 24GB VRAM; QLoRA: 4-bit base ~6GB + adapters fits in 24GB\n",
      "\n",
      "app = modal.App(\"asrs-finetune\")\n",
      "\n",
      "train_image = (\n",
      "    modal.Image.debian_s\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Verify scripts/modal_few_shot.py and scripts/modal_finetune.py\n",
    "\n",
    "few_shot_path = os.path.join(SCRIPTS_DIR, \"modal_few_shot.py\")\n",
    "finetune_path = os.path.join(SCRIPTS_DIR, \"modal_finetune.py\")\n",
    "\n",
    "if os.path.exists(few_shot_path) and os.path.exists(finetune_path):\n",
    "    print(\"Checkpoint: few-shot and fine-tune scripts exist.\")\n",
    "    for p in [few_shot_path, finetune_path]:\n",
    "        print(f\"\\n--- {p} ---\")\n",
    "        with open(p) as f:\n",
    "            print(f.read()[:300])\n",
    "else:\n",
    "    print(\"ERROR: Modal scripts not found.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
